{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Skill Gap Analyzer Model\n",
    "\n",
    "This notebook develops and evaluates the Skill Gap Analyzer that compares\n",
    "user skills against job requirements using cosine similarity.\n",
    "\n",
    "**Inputs:**\n",
    "- `skill_taxonomy_categorized.parquet` — taxonomy with 5 categories (from notebook 05)\n",
    "- `skill_embeddings.parquet` — 384-dim vectors\n",
    "- `job_skill_mapping.parquet` — 285,659 job-skill pairs\n",
    "- ChromaDB `skill_taxonomy` collection (from notebook 05)\n",
    "\n",
    "**Outputs:**\n",
    "- ChromaDB `job_titles` collection (populated)\n",
    "- Validated `SkillGapAnalyzer` class in `ml/src/skill_gap_analyzer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, str(__import__('pathlib').Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROCESS_DIR = Path('../data/process')\n",
    "\n",
    "# Load processed data\n",
    "df_taxonomy = pd.read_parquet(PROCESS_DIR / 'skill_taxonomy_categorized.parquet')\n",
    "df_embeddings = pd.read_parquet(PROCESS_DIR / 'skill_embeddings.parquet')\n",
    "df_job_skills = pd.read_parquet(PROCESS_DIR / 'job_skill_mapping.parquet')\n",
    "\n",
    "print(f'Categorized Taxonomy: {len(df_taxonomy)} skills')\n",
    "print(f'Category distribution:')\n",
    "print(df_taxonomy['category'].value_counts())\n",
    "print(f'\\nJob-Skill Mapping: {len(df_job_skills):,} pairs')\n",
    "print(f'Unique jobs: {df_job_skills[\"job_id\"].nunique():,}')\n",
    "print(f'Unique skills: {df_job_skills[\"skill\"].nunique():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Job Title Normalization & Skill Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.src.chromadb_manager import _normalize_job_title, _aggregate_job_skills\n",
    "from ml.src.config import NOISE_SKILLS\n",
    "\n",
    "# Normalize titles\n",
    "df_job_skills['title_normalized'] = df_job_skills['job_title'].apply(_normalize_job_title)\n",
    "\n",
    "# Show distribution of jobs per normalized title\n",
    "title_counts = df_job_skills.groupby('title_normalized')['job_id'].nunique().sort_values(ascending=False)\n",
    "print(f'Total unique normalized titles: {len(title_counts)}')\n",
    "print(f'Titles with >= 3 jobs: {(title_counts >= 3).sum()}')\n",
    "print(f'\\nTop 20 job titles by frequency:')\n",
    "for title, count in title_counts.head(20).items():\n",
    "    print(f'  {title:45s} {count:5d} jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate skills per title\n",
    "title_skills = _aggregate_job_skills(df_job_skills)\n",
    "\n",
    "print(f'Aggregated {len(title_skills)} job titles with skill profiles')\n",
    "\n",
    "# Show example skill profiles\n",
    "example_titles = ['data scientist', 'software engineer', 'data analyst', 'machine learning engineer']\n",
    "\n",
    "for title in example_titles:\n",
    "    if title in title_skills:\n",
    "        info = title_skills[title]\n",
    "        print(f'\\n{title.upper()} ({info[\"job_count\"]} jobs):')\n",
    "        for s in info['skills'][:10]:\n",
    "            print(f'  {s[\"skill\"]:30s} freq={s[\"frequency\"]:.2f} ({s[\"count\"]} jobs)')\n",
    "    else:\n",
    "        # Find closest match\n",
    "        close = [t for t in title_skills if title.split()[0] in t]\n",
    "        if close:\n",
    "            print(f'\\n\"{title}\" not found. Similar: {close[:5]}')\n",
    "        else:\n",
    "            print(f'\\n\"{title}\" not found in aggregated titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: skills per title distribution\n",
    "skills_per_title = [len(info['skills']) for info in title_skills.values()]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(skills_per_title, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribution of Skills per Job Title')\n",
    "axes[0].set_xlabel('Number of Required Skills')\n",
    "axes[0].set_ylabel('Number of Job Titles')\n",
    "axes[0].axvline(np.median(skills_per_title), color='red', linestyle='--', label=f'Median: {np.median(skills_per_title):.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "jobs_per_title = [info['job_count'] for info in title_skills.values()]\n",
    "axes[1].hist(jobs_per_title, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_title('Distribution of Job Postings per Title')\n",
    "axes[1].set_xlabel('Number of Job Postings')\n",
    "axes[1].set_ylabel('Number of Job Titles')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/job_title_skill_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Populate ChromaDB `job_titles` Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.src.chromadb_manager import get_chroma_client, get_ephemeral_client, populate_job_title_collection\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Connect to ChromaDB\n",
    "try:\n",
    "    chroma_client = get_chroma_client()\n",
    "    chroma_client.heartbeat()\n",
    "    print('Connected to ChromaDB Docker instance')\n",
    "except Exception:\n",
    "    print('ChromaDB Docker not available, using ephemeral client')\n",
    "    chroma_client = get_ephemeral_client()\n",
    "\n",
    "# Populate job title collection\n",
    "job_collection, job_title_skills = populate_job_title_collection(\n",
    "    chroma_client, model=model,\n",
    "    job_skill_path=str(PROCESS_DIR / 'job_skill_mapping.parquet'),\n",
    ")\n",
    "print(f'\\nJob title collection populated: {job_collection.count()} titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify: query some job titles\n",
    "from ml.src.chromadb_manager import query_job_titles\n",
    "\n",
    "test_queries = ['data scientist', 'software engineer', 'ML engineer', 'backend developer', 'product manager']\n",
    "\n",
    "for query in test_queries:\n",
    "    embedding = model.encode(query).tolist()\n",
    "    results = query_job_titles(job_collection, embedding, n_results=5)\n",
    "    print(f'\\nQuery: \"{query}\"')\n",
    "    for r in results:\n",
    "        print(f'  → {r[\"job_title\"]:40s} sim={r[\"similarity\"]:.3f} ({r[\"job_count\"]} jobs, {r[\"skill_count\"]} skills)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Test Job Title Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic matching with variations\n",
    "variations = [\n",
    "    ('ML engineer', 'Should match machine learning engineer'),\n",
    "    ('backend dev', 'Should match backend developer'),\n",
    "    ('data analyst', 'Should match data analyst'),\n",
    "    ('devops engineer', 'Should match devops or similar'),\n",
    "    ('AI researcher', 'Should match AI/ML research roles'),\n",
    "    ('frontend developer', 'Should match frontend/web developer'),\n",
    "    ('cloud architect', 'Should match cloud/infrastructure roles'),\n",
    "    ('fullstack developer', 'Should match full stack roles'),\n",
    "    ('business analyst', 'Should match business/data analyst'),\n",
    "    ('cybersecurity analyst', 'Should match security roles'),\n",
    "]\n",
    "\n",
    "print('Job Title Semantic Search Results:\\n')\n",
    "for query, expected in variations:\n",
    "    embedding = model.encode(query).tolist()\n",
    "    results = query_job_titles(job_collection, embedding, n_results=3)\n",
    "    top_match = results[0] if results else None\n",
    "    if top_match:\n",
    "        status = '✓' if top_match['similarity'] >= 0.5 else '~'\n",
    "        print(f'{status} \"{query:25s}\" → \"{top_match[\"job_title\"]:35s}\" (sim={top_match[\"similarity\"]:.3f})')\n",
    "    else:\n",
    "        print(f'✗ \"{query}\" → No match found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Full Gap Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure skill_taxonomy collection exists (from notebook 05)\n",
    "from ml.src.chromadb_manager import populate_skill_collection\n",
    "\n",
    "try:\n",
    "    chroma_client.get_collection('skill_taxonomy')\n",
    "    print('skill_taxonomy collection already exists')\n",
    "except Exception:\n",
    "    print('Populating skill_taxonomy collection...')\n",
    "    populate_skill_collection(\n",
    "        chroma_client,\n",
    "        taxonomy_path=str(PROCESS_DIR / 'skill_taxonomy_categorized.parquet'),\n",
    "        embeddings_path=str(PROCESS_DIR / 'skill_embeddings.parquet'),\n",
    "    )\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.src.skill_gap_analyzer import SkillGapAnalyzer\n",
    "from ml.src.skill_extractor import SkillExtractor\n",
    "\n",
    "# Initialize both models\n",
    "extractor = SkillExtractor(\n",
    "    chroma_client=chroma_client, model=model,\n",
    "    taxonomy_path=str(PROCESS_DIR / 'skill_taxonomy_categorized.parquet'),\n",
    ")\n",
    "\n",
    "analyzer = SkillGapAnalyzer(\n",
    "    chroma_client=chroma_client, model=model,\n",
    "    job_skill_path=str(PROCESS_DIR / 'job_skill_mapping.parquet'),\n",
    "    taxonomy_path=str(PROCESS_DIR / 'skill_taxonomy_categorized.parquet'),\n",
    "    embeddings_path=str(PROCESS_DIR / 'skill_embeddings.parquet'),\n",
    ")\n",
    "\n",
    "print('Models initialized successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Junior Developer → Data Scientist (large gap expected)\n",
    "user_skills_1 = extractor.extract_from_skill_list('Python, SQL, Excel, Statistics, Git')\n",
    "result_1 = analyzer.analyze(user_skills_1, 'Data Scientist')\n",
    "\n",
    "print('SCENARIO 1: Junior Developer → Data Scientist')\n",
    "print(f'Matched job title: \"{result_1.job_title_matched}\" (confidence: {result_1.job_title_confidence:.3f})')\n",
    "print(f'Readiness score: {result_1.overall_readiness_score:.1%}')\n",
    "print(f'\\nMatched skills ({len(result_1.matched_skills)}):')\n",
    "for m in result_1.matched_skills:\n",
    "    print(f'  ✓ {m.user_skill:25s} → {m.required_skill:25s} [{m.category}] sim={m.similarity:.3f}')\n",
    "print(f'\\nMissing skills ({len(result_1.missing_skills)}):')\n",
    "for m in result_1.missing_skills[:10]:\n",
    "    print(f'  ✗ {m.skill_name:25s} [{m.category:20s}] freq={m.frequency:.2f}')\n",
    "print(f'\\nCategory breakdown:')\n",
    "for cat, score in result_1.category_breakdown.items():\n",
    "    bar = '█' * int(score.coverage_pct * 20) + '░' * (20 - int(score.coverage_pct * 20))\n",
    "    print(f'  {cat:25s} {bar} {score.coverage_pct:.0%} ({score.user_has}/{score.total_required})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Data Analyst → Data Scientist (small gap expected)\n",
    "user_skills_2 = extractor.extract_from_skill_list(\n",
    "    'Python, SQL, Statistics, Data Visualization, Tableau, Machine Learning, Pandas, Excel, PowerBI'\n",
    ")\n",
    "result_2 = analyzer.analyze(user_skills_2, 'Data Scientist')\n",
    "\n",
    "print('SCENARIO 2: Data Analyst → Data Scientist')\n",
    "print(f'Matched job title: \"{result_2.job_title_matched}\" (confidence: {result_2.job_title_confidence:.3f})')\n",
    "print(f'Readiness score: {result_2.overall_readiness_score:.1%}')\n",
    "print(f'\\nMatched skills ({len(result_2.matched_skills)}):')\n",
    "for m in result_2.matched_skills:\n",
    "    print(f'  ✓ {m.user_skill:25s} → {m.required_skill:25s} sim={m.similarity:.3f}')\n",
    "print(f'\\nMissing skills ({len(result_2.missing_skills)}):')\n",
    "for m in result_2.missing_skills[:10]:\n",
    "    print(f'  ✗ {m.skill_name:25s} [{m.category:20s}] freq={m.frequency:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Non-tech → Frontend Developer (career switch)\n",
    "user_skills_3 = extractor.extract_from_skill_list(\n",
    "    'Communication, Project Management, Microsoft Office, Teamwork, Problem Solving'\n",
    ")\n",
    "result_3 = analyzer.analyze(user_skills_3, 'Frontend Developer')\n",
    "\n",
    "print('SCENARIO 3: Non-tech → Frontend Developer (career switch)')\n",
    "print(f'Matched job title: \"{result_3.job_title_matched}\" (confidence: {result_3.job_title_confidence:.3f})')\n",
    "print(f'Readiness score: {result_3.overall_readiness_score:.1%}')\n",
    "print(f'\\nMatched skills ({len(result_3.matched_skills)}):')\n",
    "for m in result_3.matched_skills:\n",
    "    print(f'  ✓ {m.user_skill:25s} → {m.required_skill:25s} sim={m.similarity:.3f}')\n",
    "print(f'\\nMissing skills ({len(result_3.missing_skills)}):')\n",
    "for m in result_3.missing_skills[:15]:\n",
    "    print(f'  ✗ {m.skill_name:25s} [{m.category:20s}] freq={m.frequency:.2f}')\n",
    "print(f'\\nCategory breakdown:')\n",
    "for cat, score in result_3.category_breakdown.items():\n",
    "    bar = '█' * int(score.coverage_pct * 20) + '░' * (20 - int(score.coverage_pct * 20))\n",
    "    print(f'  {cat:25s} {bar} {score.coverage_pct:.0%} ({score.user_has}/{score.total_required})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Visualization: Radar Chart & Gap Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gap_analysis(result, title='Skill Gap Analysis'):\n",
    "    \"\"\"Visualize gap analysis with radar chart and missing skills bar chart.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6),\n",
    "                             subplot_kw={'polar': True} if False else {})\n",
    "    \n",
    "    # --- Radar Chart (Category Coverage) ---\n",
    "    ax1 = fig.add_subplot(121, polar=True)\n",
    "    categories = list(result.category_breakdown.keys())\n",
    "    if not categories:\n",
    "        ax1.text(0.5, 0.5, 'No category data', transform=ax1.transAxes, ha='center')\n",
    "    else:\n",
    "        values = [result.category_breakdown[c].coverage_pct for c in categories]\n",
    "        # Short labels for readability\n",
    "        short_labels = [c.replace('_', '\\n') for c in categories]\n",
    "        \n",
    "        N = len(categories)\n",
    "        angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "        values += values[:1]\n",
    "        angles += angles[:1]\n",
    "        \n",
    "        ax1.plot(angles, values, 'o-', linewidth=2, color='#2196F3')\n",
    "        ax1.fill(angles, values, alpha=0.25, color='#2196F3')\n",
    "        ax1.set_xticks(angles[:-1])\n",
    "        ax1.set_xticklabels(short_labels, size=8)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.set_title(f'Category Coverage\\nReadiness: {result.overall_readiness_score:.0%}', pad=20)\n",
    "    \n",
    "    # --- Missing Skills Bar Chart ---\n",
    "    axes[1].clear() if hasattr(axes, '__len__') else None\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    missing = result.missing_skills[:15]  # top 15\n",
    "    if missing:\n",
    "        skill_names = [m.skill_name for m in missing]\n",
    "        frequencies = [m.frequency for m in missing]\n",
    "        colors_map = {\n",
    "            'tech_skills': '#2196F3', 'soft_skills': '#4CAF50',\n",
    "            'leadership': '#FF9800', 'domain_knowledge': '#9C27B0',\n",
    "            'adaptation_skills': '#F44336'\n",
    "        }\n",
    "        bar_colors = [colors_map.get(m.category, '#999') for m in missing]\n",
    "        \n",
    "        y_pos = range(len(skill_names))\n",
    "        ax2.barh(y_pos, frequencies, color=bar_colors, edgecolor='white')\n",
    "        ax2.set_yticks(y_pos)\n",
    "        ax2.set_yticklabels(skill_names, fontsize=9)\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.set_xlabel('Importance (frequency in job postings)')\n",
    "        ax2.set_title('Top Missing Skills (Gap)')\n",
    "        \n",
    "        # Add legend\n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [Patch(facecolor=c, label=l.replace('_', ' ').title())\n",
    "                          for l, c in colors_map.items()\n",
    "                          if l in {m.category for m in missing}]\n",
    "        ax2.legend(handles=legend_elements, loc='lower right', fontsize=8)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No missing skills!', transform=ax2.transAxes,\n",
    "                ha='center', va='center', fontsize=14, color='green')\n",
    "    \n",
    "    fig.suptitle(f'{title}\\nTarget: {result.job_title_matched}', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Plot all 3 scenarios\n",
    "for i, (result, label) in enumerate([\n",
    "    (result_1, 'Scenario 1: Junior Dev → Data Scientist'),\n",
    "    (result_2, 'Scenario 2: Data Analyst → Data Scientist'),\n",
    "    (result_3, 'Scenario 3: Non-tech → Frontend Developer'),\n",
    "], 1):\n",
    "    fig = plot_gap_analysis(result, label)\n",
    "    fig.savefig(f'figures/gap_analysis_scenario_{i}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge case 1: User has no skills\n",
    "print('EDGE CASE 1: No user skills')\n",
    "result_empty = analyzer.analyze([], 'Data Scientist')\n",
    "print(f'  Readiness: {result_empty.overall_readiness_score:.1%}')\n",
    "print(f'  Matched: {len(result_empty.matched_skills)}, Missing: {len(result_empty.missing_skills)}')\n",
    "\n",
    "# Edge case 2: Unknown/rare job title\n",
    "print('\\nEDGE CASE 2: Unknown job title')\n",
    "result_unknown = analyzer.analyze(\n",
    "    extractor.extract_from_skill_list('Python, SQL'),\n",
    "    'Quantum Blockchain AI Specialist'\n",
    ")\n",
    "print(f'  Matched title: \"{result_unknown.job_title_matched}\"')\n",
    "print(f'  Confidence: {result_unknown.job_title_confidence:.3f}')\n",
    "print(f'  Readiness: {result_unknown.overall_readiness_score:.1%}')\n",
    "\n",
    "# Edge case 3: User has all required skills\n",
    "print('\\nEDGE CASE 3: User has many overlapping skills')\n",
    "# Get the top skills for a common title and use them as user skills\n",
    "if 'data scientist' in job_title_skills:\n",
    "    top_skills_ds = [s['skill'] for s in job_title_skills['data scientist']['skills'][:15]]\n",
    "    result_full = analyzer.analyze(top_skills_ds, 'Data Scientist')\n",
    "    print(f'  User has {len(top_skills_ds)} skills matching top required skills')\n",
    "    print(f'  Readiness: {result_full.overall_readiness_score:.1%}')\n",
    "    print(f'  Matched: {len(result_full.matched_skills)}, Missing: {len(result_full.missing_skills)}')\n",
    "else:\n",
    "    print('  (data scientist not found in aggregated titles)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end test: Raw CV text → SkillExtractor → SkillGapAnalyzer → Result\n",
    "print('END-TO-END TEST:')\n",
    "print('='*60)\n",
    "\n",
    "cv_text = \"\"\"I am a software engineer with 3 years of experience building web applications.\n",
    "Proficient in Python, JavaScript, React, and Node.js. I have worked with PostgreSQL\n",
    "and MongoDB databases. Experience with Docker and basic AWS deployments.\n",
    "Strong team player with good communication skills.\"\"\"\n",
    "\n",
    "print(f'Input CV text:\\n{cv_text}\\n')\n",
    "\n",
    "# Step 1: Extract skills\n",
    "extracted = extractor.extract_from_text(cv_text)\n",
    "print(f'Step 1 - Extracted {len(extracted)} skills:')\n",
    "for s in extracted:\n",
    "    print(f'  {s.skill_name:25s} [{s.category}] conf={s.confidence:.3f}')\n",
    "\n",
    "# Step 2: Analyze gap\n",
    "target_job = 'Senior Data Engineer'\n",
    "print(f'\\nStep 2 - Gap analysis for target: \"{target_job}\"')\n",
    "gap_result = analyzer.analyze(extracted, target_job)\n",
    "\n",
    "print(f'  Matched title: \"{gap_result.job_title_matched}\" (conf: {gap_result.job_title_confidence:.3f})')\n",
    "print(f'  Readiness: {gap_result.overall_readiness_score:.1%}')\n",
    "print(f'  Matched: {len(gap_result.matched_skills)} skills')\n",
    "print(f'  Missing: {len(gap_result.missing_skills)} skills')\n",
    "\n",
    "# Step 3: Convert to JSON (for API response)\n",
    "result_json = gap_result.to_dict()\n",
    "print(f'\\nStep 3 - JSON output keys: {list(result_json.keys())}')\n",
    "print(f'JSON serializable: {json.dumps(result_json) is not None}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n✅ Notebook 06 complete.')\n",
    "print('Artifacts produced:')\n",
    "print('  - ChromaDB job_titles collection (populated)')\n",
    "print('  - SkillGapAnalyzer class validated in ml/src/skill_gap_analyzer.py')\n",
    "print('  - Gap analysis visualizations in figures/')\n",
    "print('\\nBoth models are ready for FastAPI backend integration.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
