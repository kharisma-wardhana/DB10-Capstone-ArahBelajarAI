{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Skill Extraction & Normalization\n",
    "\n",
    "This notebook extracts skills from all cleaned job datasets, normalizes them into a unified taxonomy, and creates the job-skill mapping used for EDA and ML feature engineering.\n",
    "\n",
    "**Inputs:** Cleaned parquet files from Notebook 01\n",
    "\n",
    "**Outputs:**\n",
    "- `skill_taxonomy.parquet` - Master skill vocabulary\n",
    "- `skill_synonyms.json` - Synonym mapping dictionary\n",
    "- `job_skill_mapping.parquet` - Exploded (job, skill) pairs with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setup & Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets:\n",
      "  future_jobs                   10,000 rows\n",
      "  india_jobs                        32 rows\n",
      "  job_market                       250 rows\n",
      "  jobstreet                     18,204 rows\n",
      "  linkedin_job_skills          213,768 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RAW_DIR = Path('../data/raw')\n",
    "PROCESS_DIR = Path('../data/process')\n",
    "\n",
    "# Load cleaned datasets\n",
    "df_future = pd.read_parquet(PROCESS_DIR / 'cleaned_future_jobs.parquet')\n",
    "df_india = pd.read_parquet(PROCESS_DIR / 'cleaned_india_jobs.parquet')\n",
    "df_market = pd.read_parquet(PROCESS_DIR / 'cleaned_job_market.parquet')\n",
    "df_jobstreet = pd.read_parquet(PROCESS_DIR / 'cleaned_jobstreet.parquet')\n",
    "df_linkedin_skills = pd.read_parquet(PROCESS_DIR / 'linkedin_skills_taxonomy.parquet')\n",
    "df_linkedin_job_skills = pd.read_parquet(PROCESS_DIR / 'linkedin_job_skills.parquet')\n",
    "\n",
    "print('Loaded datasets:')\n",
    "for name, df in [('future_jobs', df_future), ('india_jobs', df_india), \n",
    "                  ('job_market', df_market), ('jobstreet', df_jobstreet),\n",
    "                  ('linkedin_job_skills', df_linkedin_job_skills)]:\n",
    "    print(f'  {name:25s} {len(df):>10,} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Skill Synonym Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonym dictionary: 54 entries\n"
     ]
    }
   ],
   "source": [
    "SKILL_SYNONYMS = {\n",
    "    # AI & ML\n",
    "    'ml': 'machine learning',\n",
    "    'ai': 'artificial intelligence',\n",
    "    'dl': 'deep learning',\n",
    "    'nlp': 'natural language processing',\n",
    "    'cv': 'computer vision',\n",
    "    'gen ai': 'generative ai',\n",
    "    'genai': 'generative ai',\n",
    "    'generative artificial intelligence': 'generative ai',\n",
    "    'rag': 'retrieval augmented generation',\n",
    "    'llm': 'large language model',\n",
    "    'llms': 'large language model',\n",
    "    'large language models': 'large language model',\n",
    "    \n",
    "    # Programming Languages\n",
    "    'js': 'javascript',\n",
    "    'ts': 'typescript',\n",
    "    'py': 'python',\n",
    "    'golang': 'go',\n",
    "    'c#': 'csharp',\n",
    "    'c++': 'cpp',\n",
    "    \n",
    "    # Frameworks & Libraries\n",
    "    'react.js': 'react',\n",
    "    'reactjs': 'react',\n",
    "    'react js': 'react',\n",
    "    'node.js': 'nodejs',\n",
    "    'node js': 'nodejs',\n",
    "    'vue.js': 'vue',\n",
    "    'vuejs': 'vue',\n",
    "    'angular.js': 'angular',\n",
    "    'angularjs': 'angular',\n",
    "    'next.js': 'nextjs',\n",
    "    'next js': 'nextjs',\n",
    "    'express.js': 'expressjs',\n",
    "    'sci-kit learn': 'scikit-learn',\n",
    "    'sklearn': 'scikit-learn',\n",
    "    'tf': 'tensorflow',\n",
    "    \n",
    "    # Cloud & DevOps\n",
    "    'aws': 'amazon web services',\n",
    "    'gcp': 'google cloud platform',\n",
    "    'google cloud': 'google cloud platform',\n",
    "    'azure cloud': 'microsoft azure',\n",
    "    'k8s': 'kubernetes',\n",
    "    'ci/cd': 'cicd',\n",
    "    'ci cd': 'cicd',\n",
    "    \n",
    "    # Databases\n",
    "    'postgres': 'postgresql',\n",
    "    'mongo': 'mongodb',\n",
    "    'sql server': 'microsoft sql server',\n",
    "    'mssql': 'microsoft sql server',\n",
    "    \n",
    "    # Data\n",
    "    'bi': 'business intelligence',\n",
    "    'power bi': 'powerbi',\n",
    "    'data science on azure': 'data science',\n",
    "    'machine learning on azure': 'machine learning',\n",
    "    'azure machine learning': 'machine learning',\n",
    "    'azure ai': 'artificial intelligence',\n",
    "    \n",
    "    # Other\n",
    "    'rest apis': 'rest api',\n",
    "    'restful api': 'rest api',\n",
    "    'restful apis': 'rest api',\n",
    "    'api management': 'api design',\n",
    "}\n",
    "\n",
    "print(f'Synonym dictionary: {len(SKILL_SYNONYMS)} entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  NLP, Machine Learning on Azure, Data science on Azure, Python, ML\n",
      "Output: ['natural language processing', 'machine learning', 'data science', 'python']\n"
     ]
    }
   ],
   "source": [
    "def normalize_skill(skill_str):\n",
    "    \"\"\"Normalize a single skill string.\"\"\"\n",
    "    if not isinstance(skill_str, str):\n",
    "        return ''\n",
    "    s = skill_str.strip().lower()\n",
    "    # Remove trailing/leading punctuation (but keep internal ones like c++, c#)\n",
    "    s = re.sub(r'^[\\s\\-\\.\\,]+|[\\s\\-\\.\\,]+$', '', s)\n",
    "    # Apply synonym mapping\n",
    "    s = SKILL_SYNONYMS.get(s, s)\n",
    "    return s\n",
    "\n",
    "def parse_skills_column(series, sep=','):\n",
    "    \"\"\"Parse a comma-separated skills column into lists of normalized skills.\"\"\"\n",
    "    def _parse(val):\n",
    "        if not isinstance(val, str) or val.strip() == '':\n",
    "            return []\n",
    "        skills = [normalize_skill(s) for s in val.split(sep)]\n",
    "        # Remove empty strings and deduplicate while preserving order\n",
    "        seen = set()\n",
    "        result = []\n",
    "        for s in skills:\n",
    "            if s and s not in seen:\n",
    "                seen.add(s)\n",
    "                result.append(s)\n",
    "        return result\n",
    "    return series.apply(_parse)\n",
    "\n",
    "# Test\n",
    "test_skills = 'NLP, Machine Learning on Azure, Data science on Azure, Python, ML'\n",
    "print(f'Input:  {test_skills}')\n",
    "print(f'Output: {parse_skills_column(pd.Series([test_skills]))[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Parse Explicit Skills (3 datasets with skills columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Jobs: 11 unique skills from 20000 total mentions\n",
      "Top 10: [('climate data analysis', 2490), ('energy modeling', 2490), ('quantum algorithms', 1690), ('tensorflow', 1690), ('ethereum', 1683), ('qiskit', 1682), ('solidity', 1669), ('linear algebra', 1666), ('python', 1657), ('rust', 1646)]\n"
     ]
    }
   ],
   "source": [
    "# Future Jobs\n",
    "df_future['skills_list'] = parse_skills_column(df_future['skills_required'])\n",
    "future_skills = [s for skills in df_future['skills_list'] for s in skills]\n",
    "print(f'Future Jobs: {len(set(future_skills))} unique skills from {len(future_skills)} total mentions')\n",
    "print(f'Top 10: {Counter(future_skills).most_common(10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India Jobs: 138 unique skills from 253 total mentions\n",
      "Top 10: [('python', 15), ('machine learning', 12), ('sql', 9), ('artificial intelligence', 7), ('natural language processing', 5), ('data science', 5), ('pyspark', 5), ('amazon web services', 5), ('project management', 5), ('data', 4)]\n"
     ]
    }
   ],
   "source": [
    "# India Jobs\n",
    "df_india['skills_list'] = parse_skills_column(df_india['skills'])\n",
    "india_skills = [s for skills in df_india['skills_list'] for s in skills]\n",
    "print(f'India Jobs: {len(set(india_skills))} unique skills from {len(india_skills)} total mentions')\n",
    "print(f'Top 10: {Counter(india_skills).most_common(10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Market: 19 unique skills from 1032 total mentions\n",
      "Top 10: [('machine learning', 71), ('python', 67), ('go', 60), ('git', 59), ('docker', 58), ('agile', 57), ('amazon web services', 56), ('cicd', 56), ('ruby', 55), ('typescript', 55)]\n"
     ]
    }
   ],
   "source": [
    "# Job Market\n",
    "df_market['skills_list'] = parse_skills_column(df_market['skills'])\n",
    "market_skills = [s for skills in df_market['skills_list'] for s in skills]\n",
    "print(f'Job Market: {len(set(market_skills))} unique skills from {len(market_skills)} total mentions')\n",
    "print(f'Top 10: {Counter(market_skills).most_common(10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Build Seed Skill Vocabulary\n",
    "\n",
    "Combine skills from:\n",
    "1. The 3 job datasets with explicit skill columns\n",
    "2. Coursera courses (50K+ courses with curated skill names)\n",
    "3. LinkedIn skill taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique skills from job datasets: 160\n",
      "Unique skills from Coursera: 2448\n",
      "LinkedIn skill categories: 35\n",
      "\n",
      "Final seed vocabulary: 2528 skills\n",
      "Sample: ['3d assets', '3d modeling', 'a/b testing', 'ability to meet deadlines', 'about different approaches to the question of how was it humanly\\xa0possible', 'about the development of nazi ideology as well as the early measures taken against the jews and others who were considered \"undesirables\"', 'about the implementation of the \"final solution\" throughout europe and the nature of local collaboration', 'about the key decisions and turning points leading to the \"final solution\"', 'academic advising', 'acceptance testing', 'accident prevention', 'accident reporting', 'account management', 'accountability', 'accounting', 'accounting and finance software', 'accounting records', 'accounting software', 'accounts payable', 'accounts payable and receivable']\n"
     ]
    }
   ],
   "source": [
    "# Collect all explicit skills from job datasets\n",
    "all_explicit_skills = set(future_skills) | set(india_skills) | set(market_skills)\n",
    "print(f'Unique skills from job datasets: {len(all_explicit_skills)}')\n",
    "\n",
    "# Add Coursera skills\n",
    "df_courses = pd.read_csv(RAW_DIR / 'courses_en.csv', usecols=['skills'])\n",
    "coursera_skills = set()\n",
    "for skills_str in df_courses['skills'].dropna():\n",
    "    for s in skills_str.split(','):\n",
    "        normalized = normalize_skill(s)\n",
    "        if normalized and len(normalized) >= 2:\n",
    "            coursera_skills.add(normalized)\n",
    "print(f'Unique skills from Coursera: {len(coursera_skills)}')\n",
    "del df_courses\n",
    "\n",
    "# Add LinkedIn skill category names (broad categories)\n",
    "linkedin_category_names = set(df_linkedin_skills['skill_name'].str.lower().tolist())\n",
    "print(f'LinkedIn skill categories: {len(linkedin_category_names)}')\n",
    "\n",
    "# Build seed vocabulary\n",
    "seed_vocabulary = all_explicit_skills | coursera_skills\n",
    "# Filter out overly generic or short terms\n",
    "seed_vocabulary = {s for s in seed_vocabulary if len(s) >= 2 and s not in {\n",
    "    'and', 'the', 'for', 'with', 'from', 'data', 'science', 'machine',\n",
    "    'senior', 'junior', 'hiring', 'generation', 'management', 'associate',\n",
    "}}\n",
    "\n",
    "print(f'\\nFinal seed vocabulary: {len(seed_vocabulary)} skills')\n",
    "print(f'Sample: {sorted(list(seed_vocabulary))[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Extract Skills from JobStreet Descriptions\n",
    "\n",
    "Since jobstreet has no explicit skills column, we extract skills from job descriptions using keyword matching against the seed vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech skill vocabulary for extraction: 2572 skills\n"
     ]
    }
   ],
   "source": [
    "# Build a more focused tech skill vocabulary for jobstreet extraction\n",
    "# Use a curated subset to reduce false positives in free text\n",
    "TECH_SKILL_VOCABULARY = {\n",
    "    # Programming languages\n",
    "    'python', 'java', 'javascript', 'typescript', 'csharp', 'cpp', 'go', 'rust',\n",
    "    'ruby', 'php', 'swift', 'kotlin', 'scala', 'r', 'matlab', 'perl',\n",
    "    'dart', 'lua', 'haskell', 'elixir', 'solidity',\n",
    "    \n",
    "    # Web frameworks\n",
    "    'react', 'angular', 'vue', 'nextjs', 'nodejs', 'django', 'flask', 'fastapi',\n",
    "    'spring boot', 'expressjs', 'laravel', 'rails', 'asp.net',\n",
    "    \n",
    "    # AI/ML\n",
    "    'machine learning', 'deep learning', 'natural language processing',\n",
    "    'computer vision', 'tensorflow', 'pytorch', 'scikit-learn', 'keras',\n",
    "    'artificial intelligence', 'generative ai', 'large language model',\n",
    "    'reinforcement learning', 'neural network', 'retrieval augmented generation',\n",
    "    \n",
    "    # Data\n",
    "    'sql', 'nosql', 'postgresql', 'mysql', 'mongodb', 'redis', 'elasticsearch',\n",
    "    'apache spark', 'hadoop', 'kafka', 'airflow', 'dbt',\n",
    "    'data engineering', 'data analysis', 'data visualization',\n",
    "    'pandas', 'numpy', 'powerbi', 'tableau', 'looker',\n",
    "    'etl', 'data warehouse', 'data pipeline', 'data modeling',\n",
    "    'big data', 'data mining', 'business intelligence',\n",
    "    \n",
    "    # Cloud & Infrastructure\n",
    "    'amazon web services', 'microsoft azure', 'google cloud platform',\n",
    "    'docker', 'kubernetes', 'terraform', 'ansible', 'jenkins',\n",
    "    'cicd', 'devops', 'linux', 'unix', 'nginx',\n",
    "    'microservices', 'serverless', 'cloud computing',\n",
    "    \n",
    "    # Security\n",
    "    'cybersecurity', 'penetration testing', 'network security',\n",
    "    'information security', 'encryption', 'firewall',\n",
    "    \n",
    "    # Mobile\n",
    "    'android', 'ios', 'react native', 'flutter', 'mobile development',\n",
    "    \n",
    "    # Tools & Practices\n",
    "    'git', 'github', 'gitlab', 'jira', 'agile', 'scrum',\n",
    "    'rest api', 'graphql', 'grpc', 'websocket',\n",
    "    'html', 'css', 'sass', 'webpack', 'vite',\n",
    "    \n",
    "    # Blockchain\n",
    "    'blockchain', 'ethereum', 'smart contract', 'web3',\n",
    "    'decentralized', 'defi', 'nft', 'cryptocurrency',\n",
    "    \n",
    "    # Emerging tech\n",
    "    'quantum computing', 'quantum algorithms', 'qiskit',\n",
    "    'iot', 'internet of things', 'edge computing',\n",
    "    'augmented reality', 'virtual reality', 'metaverse',\n",
    "    'robotics', '3d printing', 'autonomous vehicles',\n",
    "    \n",
    "    # Green tech\n",
    "    'renewable energy', 'energy modeling', 'climate data analysis',\n",
    "    'sustainability', 'carbon footprint', 'clean energy',\n",
    "    \n",
    "    # Soft skills (selected tech-relevant ones)\n",
    "    'project management', 'product management', 'system design',\n",
    "    'software architecture', 'technical leadership',\n",
    "}\n",
    "\n",
    "# Also add skills from the seed vocabulary that look like tech skills\n",
    "# (longer multi-word terms are less likely to be false positives)\n",
    "for skill in seed_vocabulary:\n",
    "    if len(skill) >= 5:  # Only add skills with 5+ chars to reduce noise\n",
    "        TECH_SKILL_VOCABULARY.add(skill)\n",
    "\n",
    "print(f'Tech skill vocabulary for extraction: {len(TECH_SKILL_VOCABULARY)} skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test extraction: ['machine learning', 'kubernetes', 'tensorflow', 'python', 'docker']\n"
     ]
    }
   ],
   "source": [
    "# Pre-compile regex patterns sorted by length (longest first) for efficient matching\n",
    "skill_patterns = []\n",
    "for skill in sorted(TECH_SKILL_VOCABULARY, key=len, reverse=True):\n",
    "    # Use word boundaries, but handle special characters in skill names\n",
    "    pattern = r'\\b' + re.escape(skill) + r'\\b'\n",
    "    try:\n",
    "        skill_patterns.append((skill, re.compile(pattern, re.IGNORECASE)))\n",
    "    except re.error:\n",
    "        pass\n",
    "\n",
    "def extract_skills_from_text(text):\n",
    "    \"\"\"Extract skills from free text using keyword matching.\"\"\"\n",
    "    if not isinstance(text, str) or len(text) < 10:\n",
    "        return []\n",
    "    text_lower = text.lower()\n",
    "    found = []\n",
    "    for skill, pattern in skill_patterns:\n",
    "        if pattern.search(text_lower):\n",
    "            found.append(skill)\n",
    "    return found\n",
    "\n",
    "# Test with a sample description\n",
    "test_desc = \"Looking for a Python developer with experience in machine learning, TensorFlow, and AWS. Knowledge of Docker and Kubernetes preferred.\"\n",
    "print(f'Test extraction: {extract_skills_from_text(test_desc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting skills from 18,204 jobstreet descriptions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1f9428bc714ef98c1bad92d7921515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting skills:   0%|          | 0/18204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jobstreet skill extraction results:\n",
      "  Jobs with >= 1 skill found: 18,094 (99.4%)\n",
      "  Average skills per job: 14.6\n",
      "  Median skills per job: 13\n",
      "  Max skills per job: 66\n",
      "\n",
      "Top 20 skills in jobstreet:\n",
      "  company                             9,643\n",
      "  engineering                         9,407\n",
      "  development                         8,256\n",
      "  communication                       7,882\n",
      "  design                              7,506\n",
      "  business                            7,395\n",
      "  environment                         5,983\n",
      "  product                             4,795\n",
      "  maintenance                         4,663\n",
      "  computer science                    4,225\n",
      "  analysis                            4,140\n",
      "  operations                          3,596\n",
      "  analytical                          3,580\n",
      "  planning                            3,360\n",
      "  delivery                            2,964\n",
      "  information technology              2,689\n",
      "  project management                  2,252\n",
      "  sales                               2,130\n",
      "  leadership                          2,128\n",
      "  construction                        2,096\n"
     ]
    }
   ],
   "source": [
    "# Extract skills from jobstreet descriptions\n",
    "print(f'Extracting skills from {len(df_jobstreet):,} jobstreet descriptions...')\n",
    "\n",
    "tqdm.pandas(desc='Extracting skills')\n",
    "df_jobstreet['skills_list'] = df_jobstreet['descriptions'].progress_apply(extract_skills_from_text)\n",
    "\n",
    "# Stats\n",
    "skills_per_job = df_jobstreet['skills_list'].apply(len)\n",
    "print(f'\\nJobstreet skill extraction results:')\n",
    "print(f'  Jobs with >= 1 skill found: {(skills_per_job > 0).sum():,} ({(skills_per_job > 0).mean()*100:.1f}%)')\n",
    "print(f'  Average skills per job: {skills_per_job.mean():.1f}')\n",
    "print(f'  Median skills per job: {skills_per_job.median():.0f}')\n",
    "print(f'  Max skills per job: {skills_per_job.max()}')\n",
    "\n",
    "jobstreet_skills = [s for skills in df_jobstreet['skills_list'] for s in skills]\n",
    "print(f'\\nTop 20 skills in jobstreet:')\n",
    "for skill, count in Counter(jobstreet_skills).most_common(20):\n",
    "    print(f'  {skill:35s} {count:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Build Unified Skill Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique skills before filtering: 1771\n",
      "Skills after filtering (>= 3 occurrences): 1498\n"
     ]
    }
   ],
   "source": [
    "# Aggregate all skills across all datasets\n",
    "all_skill_counts = Counter()\n",
    "all_skill_sources = {}\n",
    "\n",
    "for name, df in [('future_jobs', df_future), ('india_jobs', df_india), \n",
    "                  ('job_market', df_market), ('jobstreet', df_jobstreet)]:\n",
    "    for skills in df['skills_list']:\n",
    "        for skill in skills:\n",
    "            all_skill_counts[skill] += 1\n",
    "            if skill not in all_skill_sources:\n",
    "                all_skill_sources[skill] = set()\n",
    "            all_skill_sources[skill].add(name)\n",
    "\n",
    "# Add LinkedIn broad categories\n",
    "for _, row in df_linkedin_job_skills.iterrows():\n",
    "    skill_name = row.get('skill_name', '')\n",
    "    if isinstance(skill_name, str):\n",
    "        normalized = normalize_skill(skill_name)\n",
    "        all_skill_counts[normalized] += 1\n",
    "        if normalized not in all_skill_sources:\n",
    "            all_skill_sources[normalized] = set()\n",
    "        all_skill_sources[normalized].add('linkedin')\n",
    "\n",
    "print(f'Total unique skills before filtering: {len(all_skill_counts)}')\n",
    "\n",
    "# Filter noise: remove skills appearing fewer than 3 times\n",
    "MIN_SKILL_COUNT = 3\n",
    "filtered_skills = {k: v for k, v in all_skill_counts.items() if v >= MIN_SKILL_COUNT and len(k) >= 2}\n",
    "print(f'Skills after filtering (>= {MIN_SKILL_COUNT} occurrences): {len(filtered_skills)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill Taxonomy: 1498 skills\n",
      "\n",
      "Top 30 skills:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>total_count</th>\n",
       "      <th>source_count</th>\n",
       "      <th>sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>information technology</td>\n",
       "      <td>28827</td>\n",
       "      <td>3</td>\n",
       "      <td>india_jobs, jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sales</td>\n",
       "      <td>24605</td>\n",
       "      <td>2</td>\n",
       "      <td>jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>engineering</td>\n",
       "      <td>22416</td>\n",
       "      <td>2</td>\n",
       "      <td>jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>management</td>\n",
       "      <td>20862</td>\n",
       "      <td>2</td>\n",
       "      <td>india_jobs, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>18185</td>\n",
       "      <td>1</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>health care provider</td>\n",
       "      <td>17369</td>\n",
       "      <td>1</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>business development</td>\n",
       "      <td>14515</td>\n",
       "      <td>2</td>\n",
       "      <td>jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>other</td>\n",
       "      <td>12608</td>\n",
       "      <td>1</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>design</td>\n",
       "      <td>9750</td>\n",
       "      <td>2</td>\n",
       "      <td>jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>company</td>\n",
       "      <td>9643</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>finance</td>\n",
       "      <td>9278</td>\n",
       "      <td>3</td>\n",
       "      <td>india_jobs, jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>development</td>\n",
       "      <td>8257</td>\n",
       "      <td>2</td>\n",
       "      <td>india_jobs, jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>communication</td>\n",
       "      <td>7882</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>business</td>\n",
       "      <td>7395</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>marketing</td>\n",
       "      <td>6502</td>\n",
       "      <td>2</td>\n",
       "      <td>jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>project management</td>\n",
       "      <td>6254</td>\n",
       "      <td>3</td>\n",
       "      <td>india_jobs, jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>environment</td>\n",
       "      <td>5983</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>accounting/auditing</td>\n",
       "      <td>5461</td>\n",
       "      <td>1</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>customer service</td>\n",
       "      <td>5120</td>\n",
       "      <td>2</td>\n",
       "      <td>jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>administrative</td>\n",
       "      <td>4860</td>\n",
       "      <td>1</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>product</td>\n",
       "      <td>4795</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>maintenance</td>\n",
       "      <td>4663</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>research</td>\n",
       "      <td>4574</td>\n",
       "      <td>3</td>\n",
       "      <td>india_jobs, jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>computer science</td>\n",
       "      <td>4227</td>\n",
       "      <td>2</td>\n",
       "      <td>india_jobs, jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>analysis</td>\n",
       "      <td>4140</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>analyst</td>\n",
       "      <td>3858</td>\n",
       "      <td>1</td>\n",
       "      <td>linkedin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>operations</td>\n",
       "      <td>3596</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>analytical</td>\n",
       "      <td>3582</td>\n",
       "      <td>2</td>\n",
       "      <td>india_jobs, jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>planning</td>\n",
       "      <td>3360</td>\n",
       "      <td>1</td>\n",
       "      <td>jobstreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>consulting</td>\n",
       "      <td>3266</td>\n",
       "      <td>3</td>\n",
       "      <td>india_jobs, jobstreet, linkedin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    skill_id              skill_name  total_count  source_count  \\\n",
       "0          1  information technology        28827             3   \n",
       "1          2                   sales        24605             2   \n",
       "2          3             engineering        22416             2   \n",
       "3          4              management        20862             2   \n",
       "4          5           manufacturing        18185             1   \n",
       "5          6    health care provider        17369             1   \n",
       "6          7    business development        14515             2   \n",
       "7          8                   other        12608             1   \n",
       "8          9                  design         9750             2   \n",
       "9         10                 company         9643             1   \n",
       "10        11                 finance         9278             3   \n",
       "11        12             development         8257             2   \n",
       "12        13           communication         7882             1   \n",
       "13        14                business         7395             1   \n",
       "14        15               marketing         6502             2   \n",
       "15        16      project management         6254             3   \n",
       "16        17             environment         5983             1   \n",
       "17        18     accounting/auditing         5461             1   \n",
       "18        19        customer service         5120             2   \n",
       "19        20          administrative         4860             1   \n",
       "20        21                 product         4795             1   \n",
       "21        22             maintenance         4663             1   \n",
       "22        23                research         4574             3   \n",
       "23        24        computer science         4227             2   \n",
       "24        25                analysis         4140             1   \n",
       "25        26                 analyst         3858             1   \n",
       "26        27              operations         3596             1   \n",
       "27        28              analytical         3582             2   \n",
       "28        29                planning         3360             1   \n",
       "29        30              consulting         3266             3   \n",
       "\n",
       "                            sources  \n",
       "0   india_jobs, jobstreet, linkedin  \n",
       "1               jobstreet, linkedin  \n",
       "2               jobstreet, linkedin  \n",
       "3              india_jobs, linkedin  \n",
       "4                          linkedin  \n",
       "5                          linkedin  \n",
       "6               jobstreet, linkedin  \n",
       "7                          linkedin  \n",
       "8               jobstreet, linkedin  \n",
       "9                         jobstreet  \n",
       "10  india_jobs, jobstreet, linkedin  \n",
       "11            india_jobs, jobstreet  \n",
       "12                        jobstreet  \n",
       "13                        jobstreet  \n",
       "14              jobstreet, linkedin  \n",
       "15  india_jobs, jobstreet, linkedin  \n",
       "16                        jobstreet  \n",
       "17                         linkedin  \n",
       "18              jobstreet, linkedin  \n",
       "19                         linkedin  \n",
       "20                        jobstreet  \n",
       "21                        jobstreet  \n",
       "22  india_jobs, jobstreet, linkedin  \n",
       "23            india_jobs, jobstreet  \n",
       "24                        jobstreet  \n",
       "25                         linkedin  \n",
       "26                        jobstreet  \n",
       "27            india_jobs, jobstreet  \n",
       "28                        jobstreet  \n",
       "29  india_jobs, jobstreet, linkedin  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create skill taxonomy DataFrame\n",
    "taxonomy_rows = []\n",
    "for i, (skill, count) in enumerate(sorted(filtered_skills.items(), key=lambda x: -x[1])):\n",
    "    taxonomy_rows.append({\n",
    "        'skill_id': i + 1,\n",
    "        'skill_name': skill,\n",
    "        'total_count': count,\n",
    "        'source_count': len(all_skill_sources.get(skill, set())),\n",
    "        'sources': ', '.join(sorted(all_skill_sources.get(skill, set()))),\n",
    "    })\n",
    "\n",
    "df_taxonomy = pd.DataFrame(taxonomy_rows)\n",
    "print(f'Skill Taxonomy: {len(df_taxonomy)} skills')\n",
    "print(f'\\nTop 30 skills:')\n",
    "display(df_taxonomy.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: skill_taxonomy.parquet (1498 skills)\n",
      "Saved: skill_synonyms.json (54 mappings)\n"
     ]
    }
   ],
   "source": [
    "# Save taxonomy and synonyms\n",
    "df_taxonomy.to_parquet(PROCESS_DIR / 'skill_taxonomy.parquet', index=False)\n",
    "print(f'Saved: skill_taxonomy.parquet ({len(df_taxonomy)} skills)')\n",
    "\n",
    "with open(PROCESS_DIR / 'skill_synonyms.json', 'w') as f:\n",
    "    json.dump(SKILL_SYNONYMS, f, indent=2)\n",
    "print(f'Saved: skill_synonyms.json ({len(SKILL_SYNONYMS)} mappings)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Create Exploded Job-Skill Mapping\n",
    "\n",
    "Long-format DataFrame where each row represents one (job, skill) pair with metadata for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating job-skill mappings...\n",
      "  future_jobs: 20,000 skill-job pairs\n",
      "  india_jobs: 226 skill-job pairs\n",
      "  job_market: 1,032 skill-job pairs\n"
     ]
    }
   ],
   "source": [
    "# Valid skills from taxonomy\n",
    "valid_skills = set(df_taxonomy['skill_name'])\n",
    "\n",
    "def create_exploded_mapping(df, source_name, id_col, title_col, date_col=None,\n",
    "                            industry_col=None, location_col=None, salary_col=None):\n",
    "    \"\"\"Explode skills_list and create standardized mapping rows.\"\"\"\n",
    "    rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        skills = row.get('skills_list', [])\n",
    "        if not skills:\n",
    "            continue\n",
    "        for skill in skills:\n",
    "            if skill not in valid_skills:\n",
    "                continue\n",
    "            entry = {\n",
    "                'job_id': str(row.get(id_col, '')),\n",
    "                'job_title': row.get(title_col, ''),\n",
    "                'skill': skill,\n",
    "                'source': source_name,\n",
    "                'posting_date': row.get(date_col) if date_col else pd.NaT,\n",
    "                'industry': row.get(industry_col, '') if industry_col else '',\n",
    "                'location': row.get(location_col, '') if location_col else '',\n",
    "                'salary': row.get(salary_col) if salary_col else np.nan,\n",
    "            }\n",
    "            rows.append(entry)\n",
    "    return rows\n",
    "\n",
    "print('Creating job-skill mappings...')\n",
    "\n",
    "all_mappings = []\n",
    "\n",
    "# Future Jobs\n",
    "mappings = create_exploded_mapping(\n",
    "    df_future, 'future_jobs', 'job_id', 'job_title',\n",
    "    date_col='posting_date', industry_col='industry',\n",
    "    location_col='location', salary_col='salary_usd'\n",
    ")\n",
    "all_mappings.extend(mappings)\n",
    "print(f'  future_jobs: {len(mappings):,} skill-job pairs')\n",
    "\n",
    "# India Jobs\n",
    "mappings = create_exploded_mapping(\n",
    "    df_india, 'india_jobs', 'title', 'title',\n",
    "    location_col='city_clean'\n",
    ")\n",
    "all_mappings.extend(mappings)\n",
    "print(f'  india_jobs: {len(mappings):,} skill-job pairs')\n",
    "\n",
    "# Job Market\n",
    "mappings = create_exploded_mapping(\n",
    "    df_market, 'job_market', 'job_title', 'job_title',\n",
    "    date_col='publication_date', industry_col='category',\n",
    "    location_col='location', salary_col='salary_min'\n",
    ")\n",
    "all_mappings.extend(mappings)\n",
    "print(f'  job_market: {len(mappings):,} skill-job pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing jobstreet mappings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e5df272bb84340851bb3c9332bb7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Jobstreet:   0%|          | 0/18204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  jobstreet: 264,401 skill-job pairs\n"
     ]
    }
   ],
   "source": [
    "# Jobstreet (larger, process in chunks for memory efficiency)\n",
    "print('Processing jobstreet mappings...')\n",
    "jobstreet_mappings = []\n",
    "\n",
    "for _, row in tqdm(df_jobstreet.iterrows(), total=len(df_jobstreet), desc='Jobstreet'):\n",
    "    skills = row.get('skills_list', [])\n",
    "    if not skills:\n",
    "        continue\n",
    "    for skill in skills:\n",
    "        if skill not in valid_skills:\n",
    "            continue\n",
    "        jobstreet_mappings.append({\n",
    "            'job_id': str(row.get('job_id', '')),\n",
    "            'job_title': row.get('job_title', ''),\n",
    "            'skill': skill,\n",
    "            'source': 'jobstreet',\n",
    "            'posting_date': row.get('listingDate', pd.NaT),\n",
    "            'industry': str(row.get('category', '')),\n",
    "            'location': row.get('location', ''),\n",
    "            'salary': np.nan,\n",
    "        })\n",
    "\n",
    "all_mappings.extend(jobstreet_mappings)\n",
    "print(f'  jobstreet: {len(jobstreet_mappings):,} skill-job pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Job-Skill Mapping:\n",
      "  Total rows: 285,659\n",
      "  Unique jobs: 28,143\n",
      "  Unique skills: 1,483\n",
      "\n",
      "Rows by source:\n",
      "source\n",
      "jobstreet      264401\n",
      "future_jobs     20000\n",
      "job_market       1032\n",
      "india_jobs        226\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date coverage:\n",
      "                   min        max  count\n",
      "source                                  \n",
      "future_jobs 2025-01-01 2025-12-31  20000\n",
      "india_jobs         NaT        NaT      0\n",
      "job_market  2025-11-27 2025-11-27   1032\n",
      "jobstreet          NaT        NaT      0\n"
     ]
    }
   ],
   "source": [
    "# Create final DataFrame\n",
    "df_job_skills = pd.DataFrame(all_mappings)\n",
    "df_job_skills['posting_date'] = pd.to_datetime(df_job_skills['posting_date'], errors='coerce')\n",
    "\n",
    "print(f'\\nFinal Job-Skill Mapping:')\n",
    "print(f'  Total rows: {len(df_job_skills):,}')\n",
    "print(f'  Unique jobs: {df_job_skills[\"job_id\"].nunique():,}')\n",
    "print(f'  Unique skills: {df_job_skills[\"skill\"].nunique():,}')\n",
    "print(f'\\nRows by source:')\n",
    "print(df_job_skills['source'].value_counts())\n",
    "print(f'\\nDate coverage:')\n",
    "print(df_job_skills.groupby('source')['posting_date'].agg(['min', 'max', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: job_skill_mapping.parquet (285,659 rows)\n",
      "Saved all datasets with skills_list column\n"
     ]
    }
   ],
   "source": [
    "df_job_skills.to_parquet(PROCESS_DIR / 'job_skill_mapping.parquet', index=False)\n",
    "print(f'Saved: job_skill_mapping.parquet ({len(df_job_skills):,} rows)')\n",
    "\n",
    "# Also save the updated dataframes with skills_list\n",
    "df_future.to_parquet(PROCESS_DIR / 'cleaned_future_jobs_skills.parquet', index=False)\n",
    "df_india.to_parquet(PROCESS_DIR / 'cleaned_india_jobs_skills.parquet', index=False)\n",
    "df_market.to_parquet(PROCESS_DIR / 'cleaned_job_market_skills.parquet', index=False)\n",
    "df_jobstreet.to_parquet(PROCESS_DIR / 'cleaned_jobstreet_skills.parquet', index=False)\n",
    "print('Saved all datasets with skills_list column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SKILL EXTRACTION SUMMARY\n",
      "============================================================\n",
      "Skill taxonomy size: 1498 unique normalized skills\n",
      "Total job-skill pairs: 285,659\n",
      "\n",
      "Output files:\n",
      "  cleaned_future_jobs.parquet                   0.16 MB\n",
      "  cleaned_future_jobs_skills.parquet            0.17 MB\n",
      "  cleaned_india_jobs.parquet                    0.01 MB\n",
      "  cleaned_india_jobs_skills.parquet             0.02 MB\n",
      "  cleaned_job_market.parquet                    0.02 MB\n",
      "  cleaned_job_market_skills.parquet             0.02 MB\n",
      "  cleaned_jobstreet.parquet                     20.86 MB\n",
      "  cleaned_jobstreet_skills.parquet              21.26 MB\n",
      "  job_skill_mapping.parquet                     1.16 MB\n",
      "  linkedin_job_skills.parquet                   1.25 MB\n",
      "  linkedin_skills_taxonomy.parquet              0.00 MB\n",
      "  skill_synonyms.json                           0.00 MB\n",
      "  skill_taxonomy.parquet                        0.03 MB\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print('\\n' + '=' * 60)\n",
    "print('SKILL EXTRACTION SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f'Skill taxonomy size: {len(df_taxonomy)} unique normalized skills')\n",
    "print(f'Total job-skill pairs: {len(df_job_skills):,}')\n",
    "print(f'\\nOutput files:')\n",
    "for f in sorted(PROCESS_DIR.glob('*')):\n",
    "    size_mb = f.stat().st_size / 1024**2\n",
    "    print(f'  {f.name:45s} {size_mb:.2f} MB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
