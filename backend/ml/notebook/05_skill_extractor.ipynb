{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Skill Extractor Model\n",
    "\n",
    "This notebook develops and evaluates the Skill Extractor model that extracts skills\n",
    "from user-provided text using semantic similarity.\n",
    "\n",
    "**Inputs:**\n",
    "- `skill_taxonomy.parquet` — 1,498 normalized skills\n",
    "- `skill_embeddings.parquet` — 384-dim vectors (all-MiniLM-L6-v2)\n",
    "- `skill_synonyms.json` — 54 synonym mappings\n",
    "\n",
    "**Outputs:**\n",
    "- `skill_taxonomy_categorized.parquet` — taxonomy with 5-category labels\n",
    "- ChromaDB `skill_taxonomy` collection (populated)\n",
    "- Validated `SkillExtractor` class in `ml/src/skill_extractor.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Setup & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxonomy: 1498 skills\n",
      "Embeddings: (1498, 384)\n",
      "Synonyms: 54 mappings\n",
      "\n",
      "Taxonomy columns: ['skill_id', 'skill_name', 'total_count', 'source_count', 'sources']\n",
      "Embedding columns: skill + 383 dims\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, str(__import__('pathlib').Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROCESS_DIR = Path('../data/process')\n",
    "\n",
    "# Load existing artifacts\n",
    "df_taxonomy = pd.read_parquet(PROCESS_DIR / 'skill_taxonomy.parquet')\n",
    "df_embeddings = pd.read_parquet(PROCESS_DIR / 'skill_embeddings.parquet')\n",
    "with open(PROCESS_DIR / 'skill_synonyms.json') as f:\n",
    "    synonyms = json.load(f)\n",
    "\n",
    "print(f'Taxonomy: {len(df_taxonomy)} skills')\n",
    "print(f'Embeddings: {df_embeddings.shape}')\n",
    "print(f'Synonyms: {len(synonyms)} mappings')\n",
    "print(f'\\nTaxonomy columns: {list(df_taxonomy.columns)}')\n",
    "print(f'Embedding columns: skill + {df_embeddings.shape[1]-1} dims')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Skill Category Assignment\n",
    "\n",
    "Assign each of the 1,498 skills to one of 5 categories using a seed-centroid approach:\n",
    "1. Define seed skills per category\n",
    "2. Compute centroid embedding per category\n",
    "3. Assign each skill to the nearest centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CATEGORY_SEEDS\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskill_category_classifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_category_centroids, classify_skills\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Build centroids from seed skills\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "from ml.src.config import CATEGORY_SEEDS\n",
    "from ml.src.skill_category_classifier import build_category_centroids, classify_skills\n",
    "\n",
    "# Build centroids from seed skills\n",
    "centroids = build_category_centroids(df_embeddings, CATEGORY_SEEDS)\n",
    "\n",
    "print('Category centroids built:')\n",
    "for cat, vec in centroids.items():\n",
    "    # Count how many seeds were found\n",
    "    skill_names = set(df_embeddings['skill'].values)\n",
    "    found = [s for s in CATEGORY_SEEDS[cat] if s in skill_names]\n",
    "    print(f'  {cat:25s} {len(found):2d}/{len(CATEGORY_SEEDS[cat]):2d} seeds found, centroid norm: {np.linalg.norm(vec):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all skills\n",
    "df_categorized = classify_skills(df_taxonomy, df_embeddings, centroids)\n",
    "\n",
    "print('Category distribution:')\n",
    "print(df_categorized['category'].value_counts())\n",
    "print(f'\\nAverage confidence: {df_categorized[\"category_confidence\"].mean():.3f}')\n",
    "print(f'Min confidence: {df_categorized[\"category_confidence\"].min():.3f}')\n",
    "print(f'Skills with low confidence (<0.3): {(df_categorized[\"category_confidence\"] < 0.3).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize category distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "cat_counts = df_categorized['category'].value_counts()\n",
    "colors = ['#2196F3', '#4CAF50', '#FF9800', '#9C27B0', '#F44336']\n",
    "cat_counts.plot(kind='barh', ax=axes[0], color=colors[:len(cat_counts)])\n",
    "axes[0].set_title('Skill Count per Category')\n",
    "axes[0].set_xlabel('Number of Skills')\n",
    "\n",
    "# Confidence distribution\n",
    "for cat in df_categorized['category'].unique():\n",
    "    subset = df_categorized[df_categorized['category'] == cat]\n",
    "    axes[1].hist(subset['category_confidence'], bins=20, alpha=0.5, label=cat)\n",
    "axes[1].set_title('Category Assignment Confidence Distribution')\n",
    "axes[1].set_xlabel('Cosine Similarity to Centroid')\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/skill_category_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-check: Show top 10 skills per category\n",
    "print('Top 10 skills per category (by total_count):\\n')\n",
    "for cat in ['tech_skills', 'soft_skills', 'leadership', 'domain_knowledge', 'adaptation_skills']:\n",
    "    subset = df_categorized[df_categorized['category'] == cat].nlargest(10, 'total_count')\n",
    "    skills = ', '.join(subset['skill_name'].tolist())\n",
    "    print(f'{cat}:')\n",
    "    print(f'  {skills}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save categorized taxonomy\n",
    "df_categorized.to_parquet(PROCESS_DIR / 'skill_taxonomy_categorized.parquet', index=False)\n",
    "print(f'Saved: skill_taxonomy_categorized.parquet ({len(df_categorized)} skills with categories)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Populate ChromaDB `skill_taxonomy` Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.src.chromadb_manager import get_chroma_client, get_ephemeral_client, populate_skill_collection\n",
    "\n",
    "# Use ephemeral client for notebook testing\n",
    "# Switch to get_chroma_client() when ChromaDB Docker is running\n",
    "try:\n",
    "    chroma_client = get_chroma_client()\n",
    "    chroma_client.heartbeat()\n",
    "    print('Connected to ChromaDB Docker instance')\n",
    "except Exception:\n",
    "    print('ChromaDB Docker not available, using ephemeral client')\n",
    "    chroma_client = get_ephemeral_client()\n",
    "\n",
    "# Populate skill collection\n",
    "skill_collection = populate_skill_collection(\n",
    "    chroma_client,\n",
    "    taxonomy_path=str(PROCESS_DIR / 'skill_taxonomy_categorized.parquet'),\n",
    "    embeddings_path=str(PROCESS_DIR / 'skill_embeddings.parquet'),\n",
    ")\n",
    "print(f'\\nSkill collection populated: {skill_collection.count()} skills')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify: query some known skills\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "test_queries = ['python programming', 'team leadership', 'data analysis', 'cloud infrastructure']\n",
    "test_embeddings = model.encode(test_queries).tolist()\n",
    "\n",
    "from ml.src.chromadb_manager import query_skills\n",
    "\n",
    "results = query_skills(skill_collection, test_embeddings, n_results=3)\n",
    "\n",
    "for query, matches in zip(test_queries, results):\n",
    "    print(f'\\nQuery: \"{query}\"')\n",
    "    for m in matches:\n",
    "        print(f'  → {m[\"skill_name\"]:30s} [{m[\"category\"]:20s}] sim={m[\"similarity\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Skill Extraction — Comma-Separated Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml.src.skill_extractor import SkillExtractor\n",
    "\n",
    "extractor = SkillExtractor(\n",
    "    chroma_client=chroma_client,\n",
    "    model=model,\n",
    "    threshold=0.45,\n",
    "    taxonomy_path=str(PROCESS_DIR / 'skill_taxonomy_categorized.parquet'),\n",
    ")\n",
    "\n",
    "# Test cases for comma-separated input\n",
    "test_inputs = [\n",
    "    'Python, Machine Learning, SQL, AWS',\n",
    "    'ML, JS, K8s, CI/CD',  # synonym handling\n",
    "    'data analysis, storytelling, team leadership, project management',\n",
    "    'React, TypeScript, Node.js, GraphQL, Docker',\n",
    "    'deep learning, NLP, computer vision, PyTorch',\n",
    "]\n",
    "\n",
    "for input_text in test_inputs:\n",
    "    print(f'\\nInput: \"{input_text}\"')\n",
    "    results = extractor.extract_from_skill_list(input_text)\n",
    "    for r in results:\n",
    "        conf_label = '★' if r.confidence >= 0.7 else '○'\n",
    "        print(f'  {conf_label} {r.skill_name:30s} [{r.category:20s}] conf={r.confidence:.3f} (from: \"{r.matched_from}\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Skill Extraction — Free Text Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample CV/resume paragraphs\n",
    "sample_texts = [\n",
    "    \"\"\"Experienced data scientist with 5 years of expertise in machine learning,\n",
    "    deep learning, and natural language processing. Proficient in Python, TensorFlow,\n",
    "    and PyTorch. Built recommendation systems and deployed models on AWS using Docker\n",
    "    and Kubernetes. Strong communication and presentation skills.\"\"\",\n",
    "    \n",
    "    \"\"\"Full-stack web developer specializing in React, TypeScript, and Node.js.\n",
    "    Experience with PostgreSQL, MongoDB, and Redis for database management.\n",
    "    Implemented CI/CD pipelines using GitHub Actions and Docker.\n",
    "    Agile methodology practitioner with strong problem-solving abilities.\"\"\",\n",
    "    \n",
    "    \"\"\"Project manager with PMP certification and 8 years leading cross-functional\n",
    "    teams in the fintech industry. Expert in stakeholder management, risk assessment,\n",
    "    and strategic planning. Proficient with Jira, Confluence, and data visualization\n",
    "    tools like Tableau and Power BI.\"\"\",\n",
    "]\n",
    "\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Sample {i}:')\n",
    "    print(f'{text[:100]}...')\n",
    "    print(f'{\"=\"*60}')\n",
    "    results = extractor.extract_from_text(text)\n",
    "    for r in results:\n",
    "        conf_label = '★' if r.confidence >= 0.7 else '○'\n",
    "        print(f'  {conf_label} {r.skill_name:30s} [{r.category:20s}] conf={r.confidence:.3f}')\n",
    "    print(f'  Total skills extracted: {len(results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold tuning: test different thresholds\n",
    "thresholds = [0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "\n",
    "# Use a known text with expected skills\n",
    "test_text = \"\"\"Python developer experienced in machine learning, data science,\n",
    "SQL databases, cloud computing with AWS, Docker containerization, and agile development.\"\"\"\n",
    "\n",
    "expected_skills = {'python', 'machine learning', 'data science', 'sql', \n",
    "                   'amazon web services', 'docker', 'agile', 'cloud computing'}\n",
    "\n",
    "print('Threshold tuning:')\n",
    "print(f'Expected skills: {expected_skills}\\n')\n",
    "\n",
    "for thresh in thresholds:\n",
    "    extractor_t = SkillExtractor(\n",
    "        chroma_client=chroma_client, model=model, threshold=thresh,\n",
    "        taxonomy_path=str(PROCESS_DIR / 'skill_taxonomy_categorized.parquet'),\n",
    "    )\n",
    "    results = extractor_t.extract_from_text(test_text)\n",
    "    extracted = {r.skill_name for r in results}\n",
    "    \n",
    "    tp = len(extracted & expected_skills)\n",
    "    fp = len(extracted - expected_skills)\n",
    "    fn = len(expected_skills - extracted)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f'Threshold={thresh:.2f}: extracted={len(extracted):2d}, P={precision:.2f}, R={recall:.2f}, F1={f1:.2f}')\n",
    "    if fp > 0:\n",
    "        false_pos = extracted - expected_skills\n",
    "        print(f'  False positives: {false_pos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Evaluation\n",
    "\n",
    "Evaluate the skill extractor on a hand-crafted test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation test set\n",
    "eval_cases = [\n",
    "    {\n",
    "        'input': 'Python, TensorFlow, Deep Learning, SQL',\n",
    "        'mode': 'csv',\n",
    "        'expected': {'python', 'tensorflow', 'deep learning', 'sql'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'ML, AI, NLP, K8s, AWS',\n",
    "        'mode': 'csv',\n",
    "        'expected': {'machine learning', 'artificial intelligence', 'natural language processing', 'kubernetes', 'amazon web services'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'React, Node.js, TypeScript, PostgreSQL, Docker',\n",
    "        'mode': 'csv',\n",
    "        'expected': {'react', 'nodejs', 'typescript', 'postgresql', 'docker'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'I have experience building machine learning models using Python and scikit-learn',\n",
    "        'mode': 'text',\n",
    "        'expected': {'machine learning', 'python', 'scikit-learn'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'Led a team of 10 engineers using agile methodology and managed stakeholder relationships',\n",
    "        'mode': 'text',\n",
    "        'expected': {'agile', 'team leadership', 'stakeholder management'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'Deployed microservices on Kubernetes with CI/CD pipelines using Jenkins and Docker',\n",
    "        'mode': 'text',\n",
    "        'expected': {'microservices', 'kubernetes', 'cicd', 'jenkins', 'docker'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'Data visualization expert proficient in Tableau, Power BI, and creating dashboards',\n",
    "        'mode': 'text',\n",
    "        'expected': {'data visualization', 'tableau', 'powerbi'},\n",
    "    },\n",
    "    {\n",
    "        'input': 'Experienced in cloud computing with AWS and Google Cloud Platform for scalable applications',\n",
    "        'mode': 'text',\n",
    "        'expected': {'cloud computing', 'amazon web services', 'google cloud platform'},\n",
    "    },\n",
    "]\n",
    "\n",
    "total_tp, total_fp, total_fn = 0, 0, 0\n",
    "\n",
    "for case in eval_cases:\n",
    "    if case['mode'] == 'csv':\n",
    "        results = extractor.extract_from_skill_list(case['input'])\n",
    "    else:\n",
    "        results = extractor.extract_from_text(case['input'])\n",
    "    \n",
    "    extracted = {r.skill_name for r in results}\n",
    "    expected = case['expected']\n",
    "    \n",
    "    tp = len(extracted & expected)\n",
    "    fp = len(extracted - expected)\n",
    "    fn = len(expected - extracted)\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "    \n",
    "    status = '✓' if fn == 0 and fp == 0 else '✗'\n",
    "    print(f'{status} [{case[\"mode\"]:4s}] \"{case[\"input\"][:60]}...\"')\n",
    "    if fn > 0:\n",
    "        print(f'    MISSED: {expected - extracted}')\n",
    "    if fp > 0:\n",
    "        print(f'    EXTRA:  {extracted - expected}')\n",
    "\n",
    "precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'Overall: Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}')\n",
    "print(f'TP={total_tp}, FP={total_fp}, FN={total_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n✅ Notebook 05 complete.')\n",
    "print('Artifacts produced:')\n",
    "print('  - skill_taxonomy_categorized.parquet (taxonomy with 5 categories)')\n",
    "print('  - ChromaDB skill_taxonomy collection (populated)')\n",
    "print('  - SkillExtractor class validated in ml/src/skill_extractor.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
